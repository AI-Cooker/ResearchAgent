Retrieval Augmented Generation (RAG) is a technique that can be used to improve the performance of foundation models on domain-specific tasks. RAG works by retrieving relevant data from outside the foundation model and augmenting the user's prompt with this data. This can help to improve the model's ability to answer questions or generate text that is relevant to the user's request.

To use RAG, you first need to convert your documents and any user queries into a compatible format. This can be done using embedding language models, which convert text into numerical representations. The embeddings of the user queries are then compared to the embeddings of the documents in the knowledge library. The original user prompt is then appended with relevant context from similar documents within the knowledge library. This augmented prompt is then sent to the foundation model.

You can update knowledge libraries and their relevant embeddings asynchronously. This means that you can continue to use the foundation model while you are updating the knowledge library.

For more information, see the following example notebooks:

* [Retrieval-Augmented Generation: Question Answering based on Custom Dataset](https://github.com/aws-samples/sagemaker-rag-qa)
* [Retrieval-Augmented Generation: Question Answering based on Custom Dataset with Open-sourced LangChain Library](https://github.com/aws-samples/sagemaker-rag-qa-langchain)