Retrieval Augmented Generation (RAG) is a technique that combines retrieval-based and generative models to deliver accurate responses. It is used to solve the problem of hallucinations or inaccurate information when asked about specific subject areas.

RAG works by first finding the most relevant documents to the user's query. The information from these documents is then fed into the generator to create the final response. This also allows for citations, which allows the end user to verify the sources and delve deeper into the information provided.

To illustrate how you can apply RAG in a real-world application, here's a chatbot template that uses RAG with a Pinecone vector store and the Vercel AI SDK to create an accurate, evidence-based chat experience. You can deploy the template on Vercel with one click, or run the following command to develop it locally:

npx create-next-app pinecone-vercel-starter --example "https://github.com/pinecone-io/pinecone-vercel-starter"

The chatbot combines retrieval-based and generative models to deliver accurate responses. The application integrates Vercel's AI SDK for efficient chatbot setup and streaming in edge environments. The guide section of the template covers the following steps:

Setting up a Next.js application
Creating a chatbot frontend component
Building an API endpoint using OpenAI's API for response generation
Progressively enhancing the chatbot with context-based capabilities, including context seeding, context retrieval, and displaying context segments.

By following the tutorial, you'll build a context-aware chatbot with improved user experience.