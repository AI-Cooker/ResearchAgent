What Is Retrieval-Augmented Generation? | Definition from TechTarget
Enterprise AI
Search the TechTarget Network
Login
Register
Explore the Network
TechTarget Network
Business Analytics
CIO
Data Management
ERP
Enterprise AI
AI Business Strategies
AI Careers
AI Infrastructure
AI Platforms 
AI Technologies
More Topics
Applications of AI
ML Platforms
Other Content
News
Features
Tips
Webinars
2023 IT Salary Survey Results
                                More
Answers
Conference Guides
Definitions
Opinions
Podcasts
Quizzes
Tech Accelerators
Tutorials
Videos
Sponsored Communities
Follow:
Home
AI technologies
Tech Accelerator
What is generative AI? Everything you need to know
Prev
Next
Generative AI in the enterprise raises questions for CIOs
15 of the best large language models
Download this guide1
X
Free Download
What is generative AI? Everything you need to know
The potential of AI technology has been percolating in the background for years. But when ChatGPT, the AI chatbot, began grabbing headlines in early 2023, it put generative AI in the spotlight.
This guide is your go-to manual for generative AI, covering its benefits, limits, use cases, prospects and much more.
Corporate Email Address:You forgot to provide an Email Address.This email address doesn’t appear to be valid.This email address is already registered. Please log in.You have exceeded the maximum character limit.Please provide a Corporate Email Address.I agree to TechTarget’s Terms of Use, Privacy Policy, and the transfer of my information to the United States for processing to provide me with relevant information as described in our Privacy Policy.Please check the box if you want to proceed.I agree to my information being processed by TechTarget and its Partners to contact me via phone, email, or other means regarding information relevant to my professional interests. I may unsubscribe at any time.Please check the box if you want to proceed.
By submitting my Email address I confirm that I have read and accepted the Terms of Use and Declaration of Consent.
Definition
retrieval-augmented generation 
Share this item with your network:
By
Alexander S. Gillis,
Technical Writer and Editor
What is retrieval-augmented generation?
Retrieval-augmented generation (RAG) is an artificial intelligence (AI) framework that retrieves data from external sources of knowledge to improve the quality of responses. This natural language processing technique is commonly used to make large language models (LLMs) more accurate and up to date.
LLMs are AI models that power chatbots such as OpenAI's ChatGPT and Google Bard. LLMs can understand, summarize, generate and predict new content. However, they can still be inconsistent and fail at some knowledge-intensive tasks -- especially tasks that are outside their initial training data or those that require up-to-date information and transparency about how they make their decisions. When this happens, the LLM can return false information, also known as an AI hallucination.
By retrieving information from external sources when the LLM's trained data isn't enough, the quality of LLM responses improves. Retrieving information from an online source, for example, enables the LLM to access current information that it wasn't initially trained on.
What does RAG do?
LLMs are commonly trained offline, making the model uncertain of any data that's created after the model was trained. RAG is used to retrieve data from outside the LLM, which then augments the user's prompts by adding relevant retrieved data in its response.
This article is part of
What is generative AI? Everything you need to know
Which also includes:
15 of the best large language models
Will AI replace jobs? 9 job types that might be affected
Pros and cons of AI-generated content
This process helps reduce any apparent knowledge gaps and AI hallucinations. This can be important in fields that require as much up-to-date and accurate information as possible, such as healthcare.
How to use RAG with LLMs
RAG combines information retrieval with a text generator model. External knowledge can be retrieved from data sources, online sources, application programming interfaces, databases or document repositories. 
Using the example of a chatbot, once a user inputs a prompt, RAG summarizes that prompt using keywords or semantic data. The converted data is then sent to a search platform to retrieve the requested data, which is then sorted through based on relevancy.
The LLM then synthesizes the retrieved data with the augmented prompt and its internal training data to create a generated response that can be passed to the chatbot with sourced links for the user.
An LLM using RAG can pull from both internal and external data to return a response for users, ensuring it provides relevant information.
What are the benefits of RAG?
Benefits of a RAG model include the following:
Provides current information. RAG pulls information from relevant, reliable and up-to-date sources.
Increases user trust. Users can access the model's sources, which promotes transparency and trust in the content and lets users verify its accuracy.
Reduces AI hallucinations. Because LLMs are grounded to external data, the model has less of a chance to make up or return incorrect information.
Reduces computational and financial costs. Organizations don't have to spend time and resources to continuously train the model on new data.
Synthesizes information. RAG synthesizes data by combining relevant information from retrieval and generative models to produce a response.
Easier to train. Because RAG uses retrieved knowledge sources, the need to train the LLM on a massive amount of training data is reduced.
Can be used for multiple tasks. Aside from chatbots, RAG can be fine-tuned for a variety of specific use cases, such as text summarization and dialogue systems.
Learn more about generative AI models, such as VAEs, GANs, diffusion, transformers and NeRFs.
					This was last updated in October 2023
			Continue Reading About retrieval-augmented generation
7 generative AI challenges that businesses should consider
Generative AI ethics: 8 biggest concerns
Assessing different types of generative AI applications
Pros and cons of AI-generated content
Cohesity Turing aims AI tools at backup and ransomware
				Related Terms
language modeling
Language modeling, or LM, is the use of various statistical and probabilistic techniques to determine the probability of a given ... 
							See complete definition
OpenAI
OpenAI is a private research laboratory that aims to develop and direct artificial intelligence (AI) in ways that benefit ... 
							See complete definition
Salesforce Einstein
Salesforce Einstein refers to an integrated set of artificial intelligence (AI) technologies developed for the Salesforce ... 
							See complete definition
Dig Deeper on AI technologies
Databricks improves support for generative AI models
By: Eric Avidon
15 of the best large language models
By: Ben Lutkevich
LangChain
By: Cameron Hashemi-Pour
large language models (LLMs)
By: Sean Kerner
Sponsored News
4 Things You Need to Know Now About Edge Computing
–HPE
Supporting a more diverse management team
–AWS
See More
Vendor Resources
What generative AI's rise means for the cybersecurity industry
–TechTarget ComputerWeekly.com
Fast Track Generative AI with Dell™ Poweredge™ XE9680
–Dell Technologies & Intel®
Latest TechTarget resources
							Business Analytics
							CIO
							Data Management
							ERP
Business Analytics
MicroStrategy launches new suite of generative AI tools
The longtime analytics vendor's suite incorporates LLM technology to make users more efficient by enabling them to use natural ...
Sisense unveils composable toolkit for app development
Compose SDK for Fusion is a composable set of APIs that enable developers to build customized advanced analytics applications to ...
SAS unveils plans to add generative AI to analytics suite
After holding off on integrating with LLMs until it could ensure data security and accurate outcomes, the vendor is making ...
CIO
7 challenges with blockchain adoption and how to avoid them
Organizations tend to face the same hurdles when they try to implement blockchain. Knowing what they are could be the first big ...
U.S. antitrust law enforcers defend actions, lawsuits
The FTC and DOJ, which enforce U.S. antitrust law, are focused on reining in big tech through antitrust lawsuits and revising ...
Is quantum computing overhyped?
Quantum computing may be coming to the enterprise. Here's what to understand about the benefits it promises, the risks it poses ...
Data Management
Amazon launches DataZone, a new data management service
The tech giant's new service provides data governance, collaboration and catalog capabilities that enable organizations to find ...
Databricks improves support for generative AI models
A new service enables users to easily deploy privately built language models and uses a GPU-based architecture to optimize and ...
New Boomi AI tool enables natural language data integration
The iPaaS vendor's new capabilities are aimed at increasing efficiency by enabling customers to build pipelines and manage data ...
ERP
Infor Enterprise Automation looks to ease RPA for ERP
Infor unveiled Enterprise Automation, which is designed to help customers bring RPA to Infor cloud ERP applications and Developer...
When integrating generative AI and ERP, focus on use cases
ERP vendors are rapidly introducing new AI functionality, but experts caution against the hype and advise using the ...
PLM and PDM software: Learn the differences
PLM and PDM software may seem similar, but they fulfill different needs for manufacturers. Learn the differences and which is ...
About Us
Editorial Ethics Policy
Meet The Editors
Contact Us
Advertisers
Partner with Us
Media Kit
Corporate Site
Contributors
Reprints
Answers
Definitions
E-Products
Events
Features
Guides
Opinions
Photo Stories
Quizzes
Tips
Tutorials
Videos
All Rights Reserved, 
Copyright 2018 - 2023, TechTarget
Privacy Policy
Cookie Preferences 
Cookie Preferences 
Do Not Sell or Share My Personal Information
Close
