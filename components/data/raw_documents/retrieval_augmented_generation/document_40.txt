What is RAG (Retrieval-Augmented Generation)? | by Jacky | MediumWhat is RAG (Retrieval-Augmented Generation)?JackyÂ·Follow4 min readÂ·Jun 24--1ListenShareRetrieval-augmented generation is a technique used in natural language processing that combines the power of both retrieval-based models and generative models to enhance the quality and relevance of generated text.The most primitive architecture for retrieval-augmented generation.To understand retrieval-augmented generation, letâ€™s break it down into its two main components: retrieval models and generative models.Retrieval models: These models are designed to retrieve relevant information from a given set of documents or a knowledge base. They typically use techniques like information retrieval or semantic search techniques to identify the most relevant pieces of information based on a given query. Retrieval-based models excel at finding accurate and specific information but lack the ability to generate creative or novel content.Generative models: Generative models, on the other hand, are designed to generate new content based on a given prompt or context. These LLMs (now explained all over the internet) use a large amount of training data to learn the patterns and structures of natural language. Generative models can generate creative and coherent text, but they may struggle with factual accuracy or relevance to a specific context.Now, retrieval-augmented generation combines these two approaches to overcome their individual limitations. In this framework, a retrieval-based model is used to retrieve relevant information from a knowledge base or a set of documents based on a given query or context. The retrieved information is then used as input or additional context for the generative model.By incorporating the retrieved information, the generative model can leverage the accuracy and specificity of the retrieval-based model to produce more relevant and accurate text. It helps the generative model to stay grounded in the available knowledge and generate text that aligns with the retrieved information.About retrieval modelsRetrieve models are a type of language model that focus on finding relevant information from a dataset, in response to a given query. These models can benefit from vast stores of knowledge and are usually trained to produce meaningful and context-specific results. The most common examples of retrieval models:Retrieval models are generally designed to find and rank relevant pieces of information from a dataset in response to a query. Here are some examples of popular retrieval models and algorithms:Neural Network Embeddings: Neural network embeddings (Such as OpenAIâ€™s embeddings or Cohereâ€™s embeddings) ranks documents based on their similarity in the vector space.BM25 (Best Match 25): A widely used text retrieval model based on probabilistic information retrieval theory. It ranks documents based on term frequencies and inverse document frequencies, considering both the relevance and rarity of terms within a corpus.TF-IDF (Term Frequency â€” Inverse Document Frequency): A classic information retrieval model that measures the importance of a term within a document relative to the whole corpus. It combines term frequency (how often a term appears in a document) and inverse document frequency (how rare the term is in a corpus) to rank documents in relevance.Hybrid Search: a combination of the above methodologies with different weightings.There are a few other methods but such as LDA but theyâ€™re not particularly powerful by themselves as of yet.ApplicationsRetrieval-augmented generation has several applications. For example, in question-answering systems, the retrieval-based model can find relevant passages or documents containing the answer, and the generative model can then generate a concise and coherent response based on that information. In content generation tasks, such as summarization or story writing, the retrieval-based model can provide relevant facts or context, which the generative model can use to create more informative and engaging content.In summary, retrieval-augmented generation combines the strengths of retrieval-based models and generative models to improve the quality and relevance of generated text. By leveraging the retrieval-based modelâ€™s ability to find accurate information and the generative modelâ€™s ability to produce creative text, this approach enables more robust and contextually grounded language generation systems.Building your own RAG engineThere are a few solutions out there where you can test building your own RAG engine (I will be writing and sharing my experiences on these soon!).If you are interested in an interesting open-source solution, I recommend checking out haystackLangchain also offers this but their solution right now is quite inflexible and itâ€™s not clear how results can be improved if they are badIf you are interested in writing tests as you are iterating on your RAG application â€” I recommend checking out DeepEval â€” which contains unit tests for LLMs (https://github.com/confident-ai/deepeval/tree/main/deepeval)Data ScienceLarge Language ModelsLlmRagArtificial Intelligence----1FollowWritten by Jacky50 FollowersScientist/EngineerFollowMore from JackyJackyUnderstanding SentencePiece ([Under][Standing][_Sentence][Piece])As SentencePiece is used in many cutting-edge NLP models, I decided to go into depth to explore what SentencePiece is about and understandâ€¦11 min readÂ·May 21, 2020--4JackyStop Eye-Balling If Prompts Work, How To Test LLMsThe Problem5 min readÂ·Sep 13--JackyðŸ”¥ DeepEvalâ€Šâ€”â€ŠSynthetic Data, Bulk Review, Custom Metric Logging andDeepEval v0.14 Update3 min readÂ·Sep 12--1JackyinArtificial Intelligence in Plain EnglishComparing Top-K Rankings StatisticallyFor data scientists, ML Engineers, ML developers, search engine enthusiasts.4 min readÂ·Jan 4, 2021--See all from JackyRecommended from MediumJayita BhattacharyyainGoPenAIPrimer on Vector Databases and Retrieval-Augmented Generation (RAG) using Langchain, Pinecone &â€¦Vector Databases Generation (RAG) Langchain Pinecone HuggingFace Large Language model generative ai9 min readÂ·Aug 16--1Yash KultheRetrieval Augmented Generation (RAG) with LangChain (Make your own ChatBot, with information youâ€¦Retrieval Augmented Generation (RAG) is a powerful technique that combines the strengths of large language models with external retrieval6 min readÂ·Aug 22--1ListsPredictive Modeling w/ Python20 storiesÂ·457 savesNatural Language Processing674 storiesÂ·293 savesAI Regulation6 storiesÂ·143 savesChatGPT prompts 24 storiesÂ·473 savesHeiko HotzinTowards Data ScienceRAG vs Finetuningâ€Šâ€”â€ŠWhich Is the Best Tool to Boost Your LLM Application?The definitive guide for choosing the right method for your use caseÂ·19 min readÂ·Aug 24--17Chelsy MaFoundation Model 101â€Šâ€”â€ŠDumb Down Retrieval Augmented Generation (RAG)RAG is a data augmentation technique to supplement text-to-text foundation models with information via document search.2 min readÂ·Apr 28--Haifeng LiA Tutorial on LLMGenerative artificial intelligence (GenAI), especially ChatGPT, captures everyoneâ€™s attention. The transformer based large language modelsâ€¦15 min readÂ·Sep 14--Han HELOIR, Ph.D.inArtificial CornerMongoDB and Langchain Magic: Your Beginnerâ€™s Guide to Setting Up a Generative AI app with Your Ownâ€¦Introduction:Â·7 min readÂ·Sep 12--12See more recommendationsHelpStatusWritersBlogCareersPrivacyTermsAboutText to speechTeams
